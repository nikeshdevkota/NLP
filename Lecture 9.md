# Natural Language Processing
## Lesson 9

<h3> Transformers</h3>

* Transformers were introduced in a 2017 research paper by Google researchers and quickly became the state-of-the-art approach for many natural language processing tasks.
* They replaced the previous dominant approach, recurrent neural networks (RNNs), which had limitations in processing long sequences of text.
* The key innovation of transformers is the attention mechanism, which allows the model to selectively focus on different parts of the input sequence when processing each token. 
* This attention mechanism enables the transformer to capture the relationships between different parts of the input sequence and has greatly improved the performance of natural language processing tasks.

<h3>Transformer Architecture</h3>

* Transformers consist of an encoder and a decoder. 
* The encoder processes the input sequence and generates a representation that captures the meaning of the text. 
* The decoder uses the encoder's representation to generate the output sequence, such as a translation or a summary.


<p align="center">
<img src= "https://user-images.githubusercontent.com/45029614/222999525-a4a98828-8e77-4146-9aab-cedc501fb297.svg" width="550" title="Transformers">
</p>

